services:

  abi-llm-base:
    build:
      context: ./agents/abi-llm-base
    image: abi-llm-base
    ports:
      - 11434:11434
      - 8081:8001
    environment:
      - BASELLM_HOST=0.0.0.0
      - ABI_LLM_BASE=https://abi-llmbase:8000
      - ABI_ROLE=LLM Base
      - ABI_NODE=ABI Node
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - abi-network

  semantic-layer:
    build:
      context: ./semantic_layer
      dockerfile: Dockerfile
    depends_on:
      - abi-weaviate
    ports:
      - "10100:10100"
    environment:
      AGENT_CARDS_BASE: "/app/layer/mcp_server/agent_cards"
      MODEL: "jina/jina-embeddings-v2-base-es"
      SQLLITE_DB: "abi_context.db"
      ABI_ROLE: "MCP Server"
      ABI_NODE: "ABI Node"
      OLLAMA_HOST: "http://abi-llm-base:11434"
      WEAVIATE_URL: "http://abi-weaviate:8080"
    volumes:
      - ./mcp/mcp_server:/app/mcp_server:ro
    networks:
      - abi-network
    restart: unless-stopped

  abi-weaviate:
    image: semitechnologies/weaviate:1.32.4
    depends_on:
      - abi-llm-base
    ports:
      - 8080:8080
      #- 8081:8081 Prometeus metric Optional
    environment:
      QUERY_DEFAULT_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: 'var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate-data:/var/lib/weaviate
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/v1/.well-known/ready"]
      interval: 5s
      timeout: 3s
      retries: 30
    networks:
      - abi-network

  abi-orchestrator:
    build:
      context: ./agents/orchestrator
    depends_on:
      - abi-llm-base
    ports:
      - 11435:11434
      - 8082:8002
    environment:
      - AGENT_HOST=0.0.0.0
      - AGENT_BASE=https://abi-orchestrator:8002
      - AGENT_CARD=/app/agent_cards/orchestrator_agent.json
      - MODEL_NAME=tinyllama:latest
      - ABI_ROLE=Orchestrator Agent
      - ABI_NODE=ABI AGENT
      - PYTHONPATH=/app
    volumes:
      - ollama-data:/root/.ollama
      - ./agents/orchestrator/agent:/agent
    networks:
      - abi-network
    restart: "unless-stopped"

  abi-actor:
    build:
      context: ./agents/worker_actor
    depends_on:
      - abi-orchestrator
    ports:
      - 11436:11434
      - 8083:8002
    environment:
      - AGENT_HOST=0.0.0.0
      - AGENT_BASE=https://abi-actor:8002
      - AGENT_CARD=/app/agent_cards/actor_agent.json
      - MODEL_NAME=tinyllama:latest
      - ABI_ROLE=Actor Agent
      - ABI_NODE=ABI AGENT
    volumes:
      - ollama-data:/root/.ollama
      - ./agents/worker_actor/agent:/agent
    networks:
      - abi-network
    restart: "unless-stopped"

  # abi-auditor:
  #   build:
  #     context: ./agents/auditor
  #   depends_on:
  #     - abi-orchestrator
  #   ports:
  #     - 11435:11435
  #   environment:
  #     - AGENT_HOST=0.0.0.0
  #     - AGENT_BASE=https://abi-auditor:11435
  #    - ABI_ROLE=Auditor Agent
  #    - ABI_NODE=ABI AGENT
  #   volumes:
  #     - auditor/root/.app
  #   networks:
  #     - abi-network
  #   restart: "unless-stopped"

  # abi-verifier:
  #   build:
  #     context: ./agents/verifier
  #   depends_on:
  #     - abi-auditor
  #   ports:
  #     - 11437:11437
  #   environment:
  #     - AGENT_HOST=0.0.0.0
  #     - AGENT_BASE=https://abi-verifier:11437
  #    - ABI_ROLE=Verifier Agent
  #    - ABI_NODE=ABI AGENT
  #   volumes:
  #     - verifier/root/.app
  #   networks:
  #     - abi-network
  #   restart: "unless-stopped"

  # abi-observer:
  #   build:
  #     context: ./agents/worker-observer
  #   depends_on:
  #     - abi-verifier
  #   ports:
  #     - 11439:11439
  #   environment:
  #     - AGENT_HOST=0.0.0.0
  #     - AGENT_BASE=https://abi-observer:11439
  #     - ABI_ROLE=Observer Agent
  #     - ABI_NODE=ABI AGENT
  #   volumes:
  #     - worker-observer/root/.app
  #   networks:
  #     - abi-network
  #   restart: "unless-stopped"

  #model-loader:
  #  image: curlimages/curl:latest
  #  depends_on:
  #    - abi-actor
  #  volumes:
  #    - ./agents/abi-llm-base/model-loader.sh:/model-loader.sh
  #  entrypoint: ["sh", "/etc/profile.d/model-loader.sh"]
  #  networks:
  #    - abi-network

 # mcp-neo4j:
  #  image: mcp/server:neo4j-memory
  # ports:
  #    - "7687:7687"
  #    - "7474:7474"
  # networks:
  #   - abi-network

volumes:
  ollama-data:
  weaviate-data:

networks:
  abi-network:
    driver: bridge
